{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4b61dfbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import nltk\n",
    "import string\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3b6b2b19",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Admin\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Admin\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "f=open(\"Bot Data.txt\",'r',errors='ignore')\n",
    "raw_file = f.read()\n",
    "raw_file = raw_file.lower()\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "sent_tokens = nltk.sent_tokenize(raw_file)\n",
    "word_tokens = nltk.word_tokenize(raw_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e0123efc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['data science is an interdisciplinary academic field that uses statistics, scientific computing, scientific methods, processes, algorithms and systems to extract or extrapolate knowledge and insights from noisy, structured, and unstructured data.',\n",
       " 'data science also integrates domain knowledge from the underlying application domain (e.g., natural sciences, information technology, and medicine).data science is multifaceted and can be described as a science, a research paradigm, a research method, a discipline, a workflow, and a profession.']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent_tokens[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "89812f25",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['data', 'science']"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_tokens[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "50110ae0",
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmer = nltk.stem.WordNetLemmatizer()\n",
    "def LemTokens(tokens):\n",
    "    return [lemmer.lemmatize(token) for token in tokens]\n",
    "remove_punct_dict = dict((ord(punct),None)for punct in string.punctuation)\n",
    "def LemNormalize(text):\n",
    "    return LemTokens(nltk.word_tokenize(text.lower().translate(remove_punct_dict)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fed2da8",
   "metadata": {},
   "outputs": [],
   "source": [
    "GREET_INPUTS = (\"hello\",\"hi\",\"greetings\",\"sup\",\"what's up\",\"hey\", \"good morning\")\n",
    "GREET_RESPONSES = [\"hi\",\"hey\",\"hi there\",\"hello\",\"i am glad! you are talking to me\"]\n",
    "def greet(sentence):\n",
    "    for word in sentence.split():\n",
    "        if word.lower() in GREET_INPUTS:\n",
    "            return random.choice(GREET_RESPONSES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "74c2bf2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "c98921c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def response(user_response):\n",
    "    robo1_response=\"\"\n",
    "    TfidfVec = TfidfVectorizer(tokenizer=LemNormalize, stop_words=\"english\")\n",
    "    tfidf = TfidfVec.fit_transform(sent_tokens)\n",
    "    vals = cosine_similarity(tfidf[-1],tfidf)\n",
    "    idx = vals.argsort()[0][-2]\n",
    "    flat = vals.flatten()\n",
    "    flat.sort()\n",
    "    req_tfidf = flat[-2]\n",
    "    if(req_tfidf==0):\n",
    "        robo1_response=robo1_response+\" I am sorry! I don't understand you\"\n",
    "        return robo1_response\n",
    "    else:\n",
    "        robo1_response = robo1_response+sent_tokens[idx]\n",
    "        return robo1_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb4d99f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "flag = True\n",
    "print(\"BOT: My name is stark. Let's have a conversation! Also, if you want to exit any time, Just type Bye! \")\n",
    "while (flag==True):\n",
    "    user_response = input()\n",
    "    user_response=user_response.lower()\n",
    "    if(user_response!=\"bye\"):\n",
    "        if (user_response==\"thanks\" or  user_response==\"thank you\"):\n",
    "            flag==False\n",
    "            print(\"BOT : You Are Welcome..\")\n",
    "        else:\n",
    "            sent_tokens.append(user_response)\n",
    "            word_tokens=word_tokens+nltk.word_tokenize(user_response)\n",
    "            final_words=list(set(word_tokens))\n",
    "            print(\"BOT:\",end=\"\")\n",
    "            print(response(user_response))\n",
    "            sent_tokens.remove(user_response)\n",
    "    else:\n",
    "        false=False\n",
    "        print(\"BOT: Goodbye! Take Care <3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc8a39ee",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
